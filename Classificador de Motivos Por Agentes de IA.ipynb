{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d041a774-ca42-466d-b5b3-a39247196b3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE workspace.churn.churn_reason_raw AS\n",
    "SELECT\n",
    "  Partner AS customer_id,\n",
    "  Churn,\n",
    "  CustomerFeedback_clean,\n",
    "  ai_extract(\n",
    "    CONCAT(\n",
    "      'Você é um analista de churn da operadora. ',\n",
    "      'Leia o feedback e extraia: ',\n",
    "      '(1) reason_short = motivo principal em 3 a 6 palavras; ',\n",
    "      '(2) reason_long = explicação em uma frase. ',\n",
    "      'Feedback: ',\n",
    "      CustomerFeedback_clean\n",
    "    ),\n",
    "    array(\n",
    "      'reason_short',\n",
    "      'reason_long'\n",
    "    )\n",
    "  ) AS reason_struct\n",
    "FROM workspace.churn.history_genie\n",
    "WHERE Churn = 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5262d596-178a-4237-9810-9c95b6cb1fd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  customer_id,\n",
    "  Churn,\n",
    "  CustomerFeedback_clean,\n",
    "  reason_struct.reason_short,\n",
    "  reason_struct.reason_long\n",
    "FROM workspace.churn.churn_reason_raw\n",
    "LIMIT 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a35a5f3-ab02-4748-b8cc-5461c231c451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Top motivos curtos\n",
    "SELECT\n",
    "  reason_struct,\n",
    "  COUNT(*) AS qtd\n",
    "FROM workspace.churn.churn_reason_raw\n",
    "GROUP BY reason_struct\n",
    "ORDER BY qtd DESC\n",
    "LIMIT 50;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6bd1e81-9eae-41b9-9cdb-e4e2eba03089",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Taxonomia com base no Short reason e Long Reason\n",
    "\n",
    "1. **Better deal / pricing**  \n",
    "   _Exemplos:_ encontrou oferta melhor, melhor preço, promoção concorrente, custo alto etc.\n",
    "\n",
    "2. **Technical issues / speed**  \n",
    "   _Exemplos:_ internet lenta, velocidades inconsistentes, problemas técnicos genéricos.\n",
    "\n",
    "3. **Service reliability / outages**  \n",
    "   _Exemplos:_ quedas frequentes, instabilidade, serviço “vai e volta”.\n",
    "\n",
    "4. **Product / plan mismatch**  \n",
    "   _Exemplos:_ plano sem internet, recurso esperado não incluído, tipo de serviço não atende uso.\n",
    "\n",
    "5. **Payment / billing issues**  \n",
    "   _Exemplos:_ método de pagamento inconveniente, cobrança, faturamento.\n",
    "\n",
    "6. **Personal reasons**  \n",
    "   _Exemplos:_ mudança, motivos pessoais genéricos.\n",
    "\n",
    "7. **Other / unclear**  \n",
    "   _Exemplos:_ o que não encaixar claramente acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "073a62f1-a6f2-4b93-930f-ef70cb5c75e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE workspace.churn.churn_reason_final AS\n",
    "SELECT\n",
    "  customer_id,\n",
    "  Churn,\n",
    "  CustomerFeedback_clean,\n",
    "  reason_struct.reason_short AS reason_short,\n",
    "  reason_struct.reason_long  AS reason_long,\n",
    "  ai_classify(\n",
    "    CONCAT(\n",
    "      'Motivo curto: ', reason_struct.reason_short, '. ',\n",
    "      'Motivo detalhado: ', reason_struct.reason_long, '. ',\n",
    "      'Classifique o motivo de churn em UMA das categorias abaixo.'\n",
    "    ),\n",
    "    array(\n",
    "      'Better deal / pricing',\n",
    "      'Technical issues / speed',\n",
    "      'Service reliability / outages',\n",
    "      'Product / plan mismatch',\n",
    "      'Payment / billing issues',\n",
    "      'Personal reasons',\n",
    "      'Other / unclear'\n",
    "    )\n",
    "  ) AS churn_category\n",
    "FROM workspace.churn.churn_reason_raw\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9118cfc5-9af2-41d8-8f61-95dc06caa59a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  churn_category,\n",
    "  COUNT(*) AS qtd\n",
    "FROM workspace.churn.churn_reason_final\n",
    "GROUP BY churn_category\n",
    "ORDER BY qtd DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c6c3d90-22ca-4612-b5e4-effc507ef10a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# agrega os dados\n",
    "df_counts = (\n",
    "    spark.table(\"workspace.churn.churn_reason_final\")\n",
    "         .groupBy(\"churn_category\")\n",
    "         .count()\n",
    "         .filter(\"churn_category IS NOT NULL\")\n",
    "         .orderBy(\"count\", ascending=False)\n",
    "         .toPandas()\n",
    ")\n",
    "\n",
    "categories = df_counts[\"churn_category\"]\n",
    "counts = df_counts[\"count\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(categories, counts)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Número de clientes\")\n",
    "plt.title(\"Contagem de churn por motivo\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486b225d-9877-4257-89d3-f3797c9febcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Tabelas\n",
    "df_reason = spark.table(\"workspace.churn.churn_reason_final\").alias(\"r\")\n",
    "df_hist   = spark.table(\"workspace.churn.history_genie\").alias(\"h\")\n",
    "\n",
    "# Join pela combinação (Churn, CustomerFeedback_clean)\n",
    "df_base = (\n",
    "    df_reason\n",
    "    .join(\n",
    "        df_hist,\n",
    "        (F.col(\"r.CustomerFeedback_clean\") == F.col(\"h.CustomerFeedback_clean\")) &\n",
    "        (F.col(\"r.Churn\") == F.col(\"h.Churn\")),\n",
    "        \"inner\"\n",
    "    )\n",
    "    .filter(F.col(\"r.churn_category\").isNotNull())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f6fdd1-5c45-41b6-b9f0-faa1b4dde6d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_avg_spend = (\n",
    "    df_base\n",
    "    .groupBy(\"r.churn_category\")\n",
    "    .agg(F.avg(\"h.TotalCharges\").alias(\"avg_spend\"))\n",
    "    .orderBy(F.col(\"avg_spend\").desc())\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "categories = df_avg_spend[\"churn_category\"]\n",
    "avg_spend  = df_avg_spend[\"avg_spend\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(categories, avg_spend)\n",
    "\n",
    "plt.ylim(0, max(avg_spend) * 1.15)\n",
    "\n",
    "# valor médio em cima de cada barra\n",
    "for bar, value in zip(bars, avg_spend):\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f\"{value:,.2f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Gasto total médio (TotalCharges)\")\n",
    "plt.title(\"Gasto total médio por motivo de churn\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d97b0cd3-5b8e-46da-b8ee-b42b70ea7c45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_avg_tenure = (\n",
    "    df_base\n",
    "    .groupBy(\"r.churn_category\")\n",
    "    .agg(F.avg(\"h.tenure\").alias(\"avg_tenure\"))\n",
    "    .orderBy(F.col(\"avg_tenure\").desc())\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "categories = df_avg_tenure[\"churn_category\"]\n",
    "avg_tenure = df_avg_tenure[\"avg_tenure\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(categories, avg_tenure)\n",
    "\n",
    "plt.ylim(0, max(avg_tenure) * 1.15)\n",
    "\n",
    "for bar, value in zip(bars, avg_tenure):\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        f\"{value:,.1f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Tenure médio (meses)\")\n",
    "plt.title(\"Tempo médio de relacionamento por motivo de churn\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43f4c118-02d5-4555-8934-46b275358c3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_contract = (\n",
    "    df_base\n",
    "    .withColumn(\n",
    "        \"contract_type\",\n",
    "        F.when(F.col(\"h.Contract_One_year\"),  F.lit(\"One year\"))\n",
    "         .when(F.col(\"h.Contract_Two_year\"),  F.lit(\"Two year\"))\n",
    "         .otherwise(F.lit(\"Month-to-month\"))\n",
    "    )\n",
    "    .groupBy(\"r.churn_category\", \"contract_type\")\n",
    "    .count()\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "# Pivot para ficar motivo x tipo de contrato\n",
    "pivot = df_contract.pivot(\n",
    "    index=\"churn_category\",\n",
    "    columns=\"contract_type\",\n",
    "    values=\"count\"\n",
    ").fillna(0)\n",
    "\n",
    "pivot = pivot.sort_values(by=pivot.columns.tolist(), ascending=False)\n",
    "\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44b9d4d5-e58a-48c7-a953-75738e0eb064",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categories = pivot.index.tolist()\n",
    "contract_types = pivot.columns.tolist()\n",
    "\n",
    "x = range(len(categories))\n",
    "width = 0.25  # largura de cada barra\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, ct in enumerate(contract_types):\n",
    "    plt.bar(\n",
    "        [xi + i*width for xi in x],\n",
    "        pivot[ct].values,\n",
    "        width,\n",
    "        label=ct\n",
    "    )\n",
    "\n",
    "plt.xticks([xi + width for xi in x], categories, rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Número de clientes churnados\")\n",
    "plt.title(\"Tipo de contrato por motivo de churn\")\n",
    "plt.legend(title=\"Tipo de contrato\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6c5882-f9ca-4201-9854-90234b3a0f0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ----- recalcula a tabela, para garantir que está tudo consistente -----\n",
    "df_reason = spark.table(\"workspace.churn.churn_reason_final\").alias(\"r\")\n",
    "df_hist   = spark.table(\"workspace.churn.history_genie\").alias(\"h\")\n",
    "\n",
    "df_base = (\n",
    "    df_reason\n",
    "    .join(\n",
    "        df_hist,\n",
    "        (F.col(\"r.CustomerFeedback_clean\") == F.col(\"h.CustomerFeedback_clean\")) &\n",
    "        (F.col(\"r.Churn\") == F.col(\"h.Churn\")),\n",
    "        \"inner\"\n",
    "    )\n",
    "    .filter(F.col(\"r.churn_category\").isNotNull())\n",
    ")\n",
    "\n",
    "df_internet = (\n",
    "    df_base\n",
    "    .withColumn(\n",
    "        \"internet_service\",\n",
    "        F.when(F.col(\"h.InternetService_Fiber_optic\"), F.lit(\"Fiber optic\"))\n",
    "         .when(F.col(\"h.InternetService_No\"),          F.lit(\"No internet\"))\n",
    "         .otherwise(F.lit(\"DSL/Other\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "df_counts = (\n",
    "    df_internet\n",
    "    .groupBy(\"r.churn_category\", \"internet_service\")\n",
    "    .count()\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "pivot_pct = (\n",
    "    df_counts\n",
    "    .pivot(index=\"churn_category\", columns=\"internet_service\", values=\"count\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# converte pra porcentagem por categoria de churn\n",
    "pivot_pct = pivot_pct.div(pivot_pct.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# garante ordem fixa das colunas\n",
    "internet_order = [\"DSL/Other\", \"Fiber optic\", \"No internet\"]\n",
    "pivot_pct = pivot_pct[internet_order]\n",
    "\n",
    "# ordena categorias pelo total de churn (opcional)\n",
    "pivot_pct = pivot_pct.sort_index()\n",
    "\n",
    "categories = pivot_pct.index.tolist()\n",
    "x = np.arange(len(categories))\n",
    "width = 0.25  # largura de cada barra\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for i, itype in enumerate(internet_order):\n",
    "    ax.bar(\n",
    "        x + (i - 1)*width,                 # desloca cada tipo para o lado\n",
    "        pivot_pct[itype].values,\n",
    "        width,\n",
    "        label=itype\n",
    "    )\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Participação (%)\")\n",
    "ax.set_title(\"Serviço de internet por categoria de churn (percentual)\")\n",
    "ax.legend(title=\"Tipo de internet\")\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45ae269a-4698-470d-ab75-1872134f9248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ============================\n",
    "# 1) Monta base com motivo + features\n",
    "# ============================\n",
    "df_reason = spark.table(\"workspace.churn.churn_reason_final\").alias(\"r\")\n",
    "df_hist   = spark.table(\"workspace.churn.history_genie\").alias(\"h\")\n",
    "\n",
    "df_base = (\n",
    "    df_reason\n",
    "    .join(\n",
    "        df_hist,\n",
    "        (F.col(\"r.CustomerFeedback_clean\") == F.col(\"h.CustomerFeedback_clean\")) &\n",
    "        (F.col(\"r.Churn\") == F.col(\"h.Churn\")),\n",
    "        \"inner\"\n",
    "    )\n",
    "    .filter(F.col(\"r.churn_category\").isNotNull())\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 2) Deriva tipo de pagamento a partir das dummies\n",
    "# ============================\n",
    "df_pay = (\n",
    "    df_base\n",
    "    .withColumn(\n",
    "        \"payment_type\",\n",
    "        F.when(F.col(\"h.PaymentMethod_Electronic_check\"),      F.lit(\"Electronic check\"))\n",
    "         .when(F.col(\"h.PaymentMethod_Mailed_check\"),          F.lit(\"Mailed check\"))\n",
    "         .when(F.col(\"h.PaymentMethod_Credit_card_automatic\"),F.lit(\"Credit card (automatic)\"))\n",
    "         .otherwise(F.lit(\"Bank transfer (automatic)\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 3) Tabela de contagem e % por motivo de churn\n",
    "# ============================\n",
    "df_counts = (\n",
    "    df_pay\n",
    "    .groupBy(\"r.churn_category\", \"payment_type\")\n",
    "    .count()\n",
    "    .toPandas()\n",
    ")\n",
    "\n",
    "pivot_pct = (\n",
    "    df_counts\n",
    "    .pivot(index=\"churn_category\", columns=\"payment_type\", values=\"count\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# transforma em % dentro de cada motivo de churn\n",
    "pivot_pct = pivot_pct.div(pivot_pct.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# ordem fixa dos tipos de pagamento\n",
    "payment_order = [\n",
    "    \"Electronic check\",\n",
    "    \"Mailed check\",\n",
    "    \"Credit card (automatic)\",\n",
    "    \"Bank transfer (automatic)\",\n",
    "]\n",
    "pivot_pct = pivot_pct[payment_order]\n",
    "\n",
    "# ordena motivos pelo total de casos (opcional)\n",
    "totals = df_counts.groupby(\"churn_category\")[\"count\"].sum().sort_values(ascending=False)\n",
    "pivot_pct = pivot_pct.loc[totals.index]\n",
    "\n",
    "print(\"Percentual de tipo de pagamento por motivo de churn:\")\n",
    "print(pivot_pct.round(1))\n",
    "\n",
    "# ============================\n",
    "# 4) Gráfico de barras agrupadas em %\n",
    "# ============================\n",
    "categories = pivot_pct.index.tolist()\n",
    "x = np.arange(len(categories))\n",
    "width = 0.2  # largura de cada barra\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for i, ptype in enumerate(payment_order):\n",
    "    ax.bar(\n",
    "        x + (i - (len(payment_order)-1)/2)*width,\n",
    "        pivot_pct[ptype].values,\n",
    "        width,\n",
    "        label=ptype\n",
    "    )\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Participação (%)\")\n",
    "ax.set_title(\"Tipo de pagamento por motivo de churn\")\n",
    "ax.set_ylim(0, 100)\n",
    "ax.legend(title=\"PaymentMethod\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c326156-262a-4e01-bce9-49a954fcd0ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Construção de modelos:\n",
    "#  - Modelo 1: probabilidade de churn\n",
    "#  - Modelo 2: motivo de churn (entre churnados)\n",
    "# Fonte: tabelas Spark history_genie + churn_reason_final\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 0. Carregar dados das tabelas Spark para pandas\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# Base de features (numéricas + dummies) que você usou até agora\n",
    "df_raw = spark.table(\"workspace.churn.history_genie\").toPandas()\n",
    "\n",
    "# Tabela com motivos de churn gerados por LLM\n",
    "df_reasons = (\n",
    "    spark.table(\"workspace.churn.churn_reason_final\")\n",
    "         .select(\"CustomerFeedback_clean\", \"Churn\", \"churn_category\")\n",
    "         .toPandas()\n",
    ")\n",
    "\n",
    "# Juntar pelas colunas em comum (Churn + CustomerFeedback_clean)\n",
    "df_full = df_raw.merge(\n",
    "    df_reasons,\n",
    "    on=[\"CustomerFeedback_clean\", \"Churn\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Target binário: churn sim/não (já é 0/1 em history_genie)\n",
    "df_full[\"Churn_flag\"] = df_full[\"Churn\"].astype(int)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. Definir features\n",
    "#    (vamos usar só variáveis numéricas e dummies, sem texto)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "cols_drop = [\n",
    "    \"Churn\",               # target original\n",
    "    \"Churn_flag\",          # target binário (vamos tirar de X)\n",
    "    \"churn_category\",      # target do modelo 2\n",
    "    \"CustomerFeedback\",    # texto original\n",
    "    \"CustomerFeedback_clean\",\n",
    "]\n",
    "\n",
    "feature_cols = [c for c in df_full.columns if c not in cols_drop]\n",
    "\n",
    "X_all = df_full[feature_cols]\n",
    "y_churn = df_full[\"Churn_flag\"]\n",
    "\n",
    "# numéricas (ajuste se quiser incluir/excluir)\n",
    "numeric_cols = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\", \"MonthlyIncome\"]\n",
    "\n",
    "# o resto é binário/bool (0/1 ou True/False)\n",
    "categorical_cols = [c for c in feature_cols if c not in numeric_cols]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Pipeline de pré-processamento\n",
    "# -------------------------------------------------------\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\",  OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Modelo 1 – probabilidade de churn\n",
    "# -------------------------------------------------------\n",
    "\n",
    "clf_churn = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "pipe_churn = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", clf_churn),\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all,\n",
    "    y_churn,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_churn,\n",
    ")\n",
    "\n",
    "pipe_churn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_churn.predict(X_test)\n",
    "y_proba = pipe_churn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Modelo de CHURN ===\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. Modelo 2 – motivo de churn (só para quem já churnou)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "df_churn = df_full[(df_full[\"Churn_flag\"] == 1) & df_full[\"churn_category\"].notna()].copy()\n",
    "\n",
    "X_reason = df_churn[feature_cols]\n",
    "y_reason = df_churn[\"churn_category\"]\n",
    "\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
    "    X_reason,\n",
    "    y_reason,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_reason,\n",
    ")\n",
    "\n",
    "clf_reason = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class=\"multinomial\",\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "pipe_reason = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),   # reaproveita o mesmo preprocessador\n",
    "    (\"model\", clf_reason),\n",
    "])\n",
    "\n",
    "pipe_reason.fit(Xr_train, yr_train)\n",
    "\n",
    "yr_pred = pipe_reason.predict(Xr_test)\n",
    "\n",
    "print(\"\\n=== Modelo de MOTIVO de churn (condicional) ===\")\n",
    "print(classification_report(yr_test, yr_pred, digits=3))\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5. Função para prever churn + top motivos\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def prever_churn_e_motivos(cliente_dict):\n",
    "    \"\"\"\n",
    "    cliente_dict: dicionário com as mesmas chaves de feature_cols.\n",
    "    Exemplo mínimo:\n",
    "    {\n",
    "      \"SeniorCitizen\": 0,\n",
    "      \"Partner\": 1,\n",
    "      \"Dependents\": 0,\n",
    "      \"tenure\": 12,\n",
    "      \"PhoneService\": 1,\n",
    "      ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    x = pd.DataFrame([cliente_dict])[feature_cols]\n",
    "\n",
    "    # probabilidade de churn\n",
    "    p_churn = pipe_churn.predict_proba(x)[0, 1]\n",
    "\n",
    "    # distribuição de motivos condicional a churn\n",
    "    motivo_probas = pipe_reason.predict_proba(x)[0]\n",
    "    motivos = pipe_reason.named_steps[\"model\"].classes_\n",
    "\n",
    "    order = np.argsort(motivo_probas)[::-1]\n",
    "    top_motivos = [\n",
    "        (motivos[i], float(motivo_probas[i]))\n",
    "        for i in order[:3]\n",
    "    ]\n",
    "\n",
    "    return p_churn, top_motivos\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6. Exemplo de uso (ajuste os valores conforme suas colunas)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "exemplo = {\n",
    "    # binárias 0/1\n",
    "    \"SeniorCitizen\": 0,\n",
    "    \"Partner\": 1,\n",
    "    \"Dependents\": 0,\n",
    "    \"PhoneService\": 1,\n",
    "    \"MultipleLines\": 0,\n",
    "    \"OnlineSecurity\": 0,\n",
    "    \"OnlineBackup\": 0,\n",
    "    \"DeviceProtection\": 0,\n",
    "    \"TechSupport\": 0,\n",
    "    \"StreamingTV\": 1,\n",
    "    \"StreamingMovies\": 1,\n",
    "    \"PaperlessBilling\": 1,\n",
    "    \"gender_Male\": 1,\n",
    "    \"InternetService_Fiber_optic\": 1,\n",
    "    \"InternetService_No\": 0,\n",
    "    \"Contract_One_year\": 0,\n",
    "    \"Contract_Two_year\": 0,\n",
    "    \"PaymentMethod_Credit_card_automatic\": 0,\n",
    "    \"PaymentMethod_Electronic_check\": 1,\n",
    "    \"PaymentMethod_Mailed_check\": 0,\n",
    "    # numéricas\n",
    "    \"tenure\": 12,\n",
    "    \"MonthlyCharges\": 95.0,\n",
    "    \"TotalCharges\": 1100.0,\n",
    "    \"MonthlyIncome\": 4000,\n",
    "}\n",
    "\n",
    "p_churn, top_motivos = prever_churn_e_motivos(exemplo)\n",
    "\n",
    "print(\"\\nProbabilidade de churn:\", round(p_churn, 3))\n",
    "print(\"Top motivos prováveis (condicionais a churn):\")\n",
    "for motivo, p in top_motivos:\n",
    "    print(f\"  - {motivo}: {p:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a33e69b7-45b0-4e44-92b7-e9620f3ce1f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4702460293787494,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Classificador de Motivos Por Agentes de IA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
