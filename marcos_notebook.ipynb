{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d99abd8-86e4-4307-8316-c109fae1b1ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Terra Signal Hackathon\n",
    "This notebook is provided as a starting point. Feel free to use it, discard it, modify it, or pretend it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e741f18-4b60-4e13-a3d9-041257455ebb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Pandas"
    }
   },
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14c40c2a-4dc2-42db-b4b1-92190de5a3f7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read file with pandas"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    roc_auc_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "file_path = \"./history.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53923edf-d55e-44c8-8881-4e1a8348334c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "An√°lise Explorat√≥ria e limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52c25b6e-625e-41a5-8a8e-1b7ead6f3db7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e884fcf-b432-46c3-8d45-30c863f270d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9ee06b5-ba75-4cb3-8ca3-082df5e23af1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# criando um data frame limpo\n",
    "df_clean = df.copy()\n",
    "df_clean.columns = df_clean.columns.str.strip()\n",
    "\n",
    "# limpando a coluna 'tenure'\n",
    "\n",
    "# substituindo 'unknown' por NaN e convertendo para num√©rico\n",
    "df_clean[\"tenure\"] = df_clean[\"tenure\"].replace(\"unknown\", pd.NA)\n",
    "df_clean[\"tenure\"] = pd.to_numeric(df_clean[\"tenure\"], errors=\"coerce\")\n",
    "\n",
    "# substituindo valores 0 por NaN\n",
    "df_clean.loc[df_clean[\"tenure\"] == 0, \"tenure\"] = pd.NA\n",
    "\n",
    "# preenchendo NaN com a mediana e convertendo para inteiro\n",
    "df_clean[\"tenure\"] = df_clean[\"tenure\"].fillna(df_clean[\"tenure\"].median())\n",
    "df_clean[\"tenure\"] = df_clean[\"tenure\"].astype(int)\n",
    "\n",
    "# normalizando phone service\n",
    "df_clean[\"PhoneService\"] = (\n",
    "    df_clean[\"PhoneService\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .replace({\"yes\": 1, \"no\": 0})\n",
    "    .astype(int)  # <- evitar FutureWarning\n",
    ")\n",
    "\n",
    "# normalizando multiple lines\n",
    "df_clean[\"MultipleLines\"] = (\n",
    "    df_clean[\"MultipleLines\"]\n",
    "    .replace({\"No phone service\": \"No\"})\n",
    "    .map({\"Yes\": 1, \"No\": 0})\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# normalizando colunas de internet\n",
    "internet_cols = [\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
    "    \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"\n",
    "]\n",
    "\n",
    "for col in internet_cols:\n",
    "    df_clean[col] = (\n",
    "        df_clean[col]\n",
    "        .replace({\"No internet service\": \"No\"})\n",
    "        .map({\"Yes\": 1, \"No\": 0})\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "# normalizando colunas bin√°rias\n",
    "for col in [\"Partner\", \"Dependents\", \"PaperlessBilling\"]:\n",
    "    df_clean[col] = df_clean[col].map({\"Yes\": 1, \"No\": 0}).astype(int)\n",
    "\n",
    "# convertendo total charges para num√©rico e tratando NaN\n",
    "df_clean[\"TotalCharges\"] = pd.to_numeric(df_clean[\"TotalCharges\"], errors=\"coerce\")\n",
    "df_clean[\"TotalCharges\"] = df_clean[\"TotalCharges\"].fillna(df_clean[\"TotalCharges\"].median())\n",
    "\n",
    "# limpando coluna de feedback do cliente\n",
    "df_clean[\"CustomerFeedback\"] = df_clean[\"CustomerFeedback\"].fillna(\"\").astype(str)\n",
    "df_clean[\"CustomerFeedback_clean\"] = (\n",
    "    df_clean[\"CustomerFeedback\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\"[^a-zA-Z0-9 ]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "# tratando categ√≥ricas com one-hot encoding\n",
    "cat_cols = [\n",
    "    \"gender\", \"InternetService\", \"Contract\", \"PaymentMethod\"\n",
    "]\n",
    "\n",
    "df_clean = pd.get_dummies(df_clean, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# convertendo target para bin√°rio\n",
    "df_clean[\"Churn\"] = df_clean[\"Churn\"].map({\"Yes\": 1, \"No\": 0}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f87e535-555b-4378-b790-9f1e1af91742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8983367-3b89-4f76-8338-7bc3c824e8aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "606dfe70-0016-4cb9-a396-899be10285a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"history_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "400771d1-2e0f-4d4b-a2b7-754bda19007e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5d95d17-ab35-4de1-a44f-1af840b8249f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Selecionar apenas as 3 colunas que voc√™ quer na tabela final\n",
    "df_minimal = df_clean[[\"customerID\", \"Churn\", \"CustomerFeedback_clean\"]]\n",
    "\n",
    "# Converter para Spark DataFrame\n",
    "df_spark = spark.createDataFrame(df_minimal)\n",
    "df_spark.createOrReplaceTempView(\"tmp_history_clean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfdff0c3-aaa3-4321-a435-d040654c3f55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE workspace.churn.history_clean AS\n",
    "SELECT customerID, Churn, CustomerFeedback_clean\n",
    "FROM tmp_history_clean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b48225-ae5e-4028-9d34-a9c7b77b1e38",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fake Model Example"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import datetime\n",
    "\n",
    "\n",
    "def prediction_function(input_df):\n",
    "    X = input_df[['customerID']].copy()\n",
    "    X['prediction'] = np.random.uniform(size=len(X)) >= 0.5\n",
    "    X['prediction'] = X['prediction'].map({True: 'Yes', False: 'No'})\n",
    "    return X\n",
    "\n",
    "test_df = pd.read_csv('inference.csv')\n",
    "prediction = prediction_function(test_df)\n",
    "print(prediction.head().transpose())\n",
    "# Use this code to save the prediction to a csv file for submission:\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "prediction.to_csv(f'prediction_<MY_GROUP_NAME>_{timestamp}.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "067e2b8b-05d1-4b2e-b842-3f5e210e5649",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(\n",
    "    data=df_clean,\n",
    "    x=\"Churn\",\n",
    "    hue=\"Churn\",\n",
    "    palette=\"Set2\",\n",
    "    legend=False\n",
    ")\n",
    "plt.title(\"Quantidade de Clientes: Churn vs N√£o Churn\")\n",
    "plt.xticks([0,1], [\"N√£o churn\", \"Churn\"])\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "595ea0cd-e7dd-4c42-9f50-2c10665167d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(\n",
    "    data=df_clean,\n",
    "    x=\"tenure\",\n",
    "    hue=\"Churn\",\n",
    "    multiple=\"stack\",\n",
    "    bins=40,\n",
    "    palette=\"Set2\"\n",
    ")\n",
    "plt.title(\"Distribui√ß√£o de Tenure por Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "062ae05e-fbb9-4823-88dd-a71a0480ca8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(\n",
    "    data=df_clean,\n",
    "    x=\"Churn\",\n",
    "    y=\"MonthlyCharges\",\n",
    "    hue=\"Churn\",\n",
    "    palette=\"Set2\",\n",
    "    legend=False   # evita legenda duplicada\n",
    ")\n",
    "plt.title(\"MonthlyCharges por Churn\")\n",
    "plt.xticks([0,1], [\"N√£o churn\", \"Churn\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b6608e1-c9eb-4e50-93cf-aaff84448a6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.violinplot(data=df_clean, x=\"Churn\", y=\"TotalCharges\", hue=\"Churn\", palette=\"Set2\", legend=False)\n",
    "plt.title(\"Total Charges por Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b3cc87a-a4e0-4f20-afd7-730a6d468ca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "colors = [\"#C0C0C0\", \"#2ECC71\"]\n",
    "# Reconstroi Contract\n",
    "Contract_series = df_clean.apply(\n",
    "    lambda r: (\n",
    "        \"Two year\" if r[\"Contract_Two year\"] == 1 else\n",
    "        \"One year\" if r[\"Contract_One year\"] == 1 else\n",
    "        \"Month-to-month\"\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Reconstroi InternetService\n",
    "InternetService_series = df_clean.apply(\n",
    "    lambda r: (\n",
    "        \"Fiber optic\" if r[\"InternetService_Fiber optic\"] == 1 else\n",
    "        \"No internet\" if r[\"InternetService_No\"] == 1 else\n",
    "        \"DSL\"\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Reconstroi PaymentMethod\n",
    "PaymentMethod_series = df_clean.apply(\n",
    "    lambda r: (\n",
    "        \"Credit card (automatic)\" if r[\"PaymentMethod_Credit card (automatic)\"] == 1 else\n",
    "        \"Electronic check\" if r[\"PaymentMethod_Electronic check\"] == 1 else\n",
    "        \"Mailed check\" if r[\"PaymentMethod_Mailed check\"] == 1 else\n",
    "        \"Bank transfer (automatic)\"\n",
    "    ),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66404ba4-b55f-4ebd-b367-3c51b825ff78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_stacked(series, churn, title, xlabel):\n",
    "    ct = pd.crosstab(series, churn, normalize=\"index\")\n",
    "    ct.columns = [\"No\", \"Yes\"]\n",
    "    ct.plot(kind=\"bar\", stacked=True, figsize=(7,4), color=colors)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Propor√ß√£o\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend(title=\"Churn\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08e0543a-f2ce-4f0b-af5d-8a03055e29ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_stacked(\n",
    "    Contract_series,\n",
    "    df_clean[\"Churn\"],\n",
    "    \"Composi√ß√£o: Churn vs N√£o Churn ‚Äî Contract\",\n",
    "    \"Contract Type\"\n",
    ")\n",
    "\n",
    "plot_stacked(\n",
    "    InternetService_series,\n",
    "    df_clean[\"Churn\"],\n",
    "    \"Composi√ß√£o: Churn vs N√£o Churn ‚Äî Internet Service\",\n",
    "    \"Internet Service Type\"\n",
    ")\n",
    "plot_stacked(\n",
    "    PaymentMethod_series,\n",
    "    df_clean[\"Churn\"],\n",
    "    \"Composi√ß√£o: Churn vs N√£o Churn ‚Äî Payment Method\",\n",
    "    \"Payment Method\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd3766e3-99e8-424d-8bc8-658e9a2b7813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "corr = df_clean.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", linewidths=.5)\n",
    "plt.title(\"Matriz de Correla√ß√£o - Vari√°veis Num√©ricas\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8e1cfb9-7d5f-48a0-84cb-4ddd838626c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ct_os = pd.crosstab(\n",
    "    df_clean[\"OnlineSecurity\"],\n",
    "    df_clean[\"Churn\"],\n",
    "    normalize='index'\n",
    ")\n",
    "ct_os.columns = [\"No\", \"Yes\"]\n",
    "\n",
    "ct_os.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(6,4),\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "plt.title(\"Composi√ß√£o: Churn vs N√£o Churn ‚Äî OnlineSecurity (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Propor√ß√£o\")\n",
    "plt.xlabel(\"OnlineSecurity\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(title=\"Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c896df-be9c-4094-be10-eebc03ed134e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ct_ts = pd.crosstab(\n",
    "    df_clean[\"TechSupport\"],\n",
    "    df_clean[\"Churn\"],\n",
    "    normalize='index'\n",
    ")\n",
    "ct_ts.columns = [\"No\", \"Yes\"]\n",
    "\n",
    "ct_ts.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(6,4),\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "plt.title(\"Composi√ß√£o: Churn vs N√£o Churn ‚Äî TechSupport (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Propor√ß√£o\")\n",
    "plt.xlabel(\"TechSupport\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(title=\"Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e668351-2e16-40bf-96f3-f6dd9a657929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ct_stv = pd.crosstab(\n",
    "    df_clean[\"StreamingTV\"],\n",
    "    df_clean[\"Churn\"],\n",
    "    normalize='index'\n",
    ")\n",
    "ct_stv.columns = [\"No\", \"Yes\"]\n",
    "\n",
    "ct_stv.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(6,4),\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "plt.title(\"Composi√ß√£o: Churn vs N√£o Churn ‚Äî StreamingTV (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Propor√ß√£o\")\n",
    "plt.xlabel(\"StreamingTV\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(title=\"Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26b269cd-e226-4b12-9e00-e5ae5f83dbb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ct_pb = pd.crosstab(\n",
    "    df_clean[\"PaperlessBilling\"],\n",
    "    df_clean[\"Churn\"],\n",
    "    normalize='index'\n",
    ")\n",
    "ct_pb.columns = [\"No\", \"Yes\"]\n",
    "\n",
    "ct_pb.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(6,4),\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "plt.title(\"Composi√ß√£o: Churn ‚Äî Paperless Billing (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Propor√ß√£o\")\n",
    "plt.xlabel(\"Paperless Billing\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(title=\"Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92090fb4-bf92-4276-8abf-047ad2ac481e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.boxplot(x=InternetService_series, y=df_clean[\"MonthlyCharges\"])\n",
    "plt.title(\"Distribui√ß√£o de MonthlyCharges por Tipo de Internet\")\n",
    "plt.xlabel(\"Internet Service Type\")\n",
    "plt.ylabel(\"MonthlyCharges\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=Contract_series, y=df_clean[\"MonthlyCharges\"])\n",
    "plt.title(\"Distribui√ß√£o de MonthlyCharges por Tipo de Contract\")\n",
    "plt.xlabel(\"Contract Type\")\n",
    "plt.ylabel(\"MonthlyCharges\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=PaymentMethod_series, y=df_clean[\"MonthlyCharges\"])\n",
    "plt.title(\"Distribui√ß√£o de MonthlyCharges por Payment Method\")\n",
    "plt.xlabel(\"Payment Method\")\n",
    "plt.ylabel(\"MonthlyCharges\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac6c0b90-4d8e-41d5-808f-aca0ce8c8e08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Conclus√µes Completas da An√°lise Explorat√≥ria\n",
    "\n",
    "## 1. Distribui√ß√£o geral do churn\n",
    "O gr√°fico de contagem mostra que a maioria dos clientes n√£o churnou, com churn representando uma minoria relevante.  \n",
    "Isso revela um desbalanceamento natural da vari√°vel-alvo, mas n√£o impede a an√°lise explorat√≥ria.\n",
    "\n",
    "## 2. Rela√ß√£o entre tenure e churn\n",
    "O histograma mostra um padr√£o claro:\n",
    "- Clientes com tenure muito baixo apresentam alta incid√™ncia de churn.\n",
    "- Conforme o tenure aumenta, a propor√ß√£o de churn cai drasticamente.\n",
    "- Clientes com tenure muito alto quase n√£o apresentam churn.\n",
    "\n",
    "Conclus√£o: churn √© predominantemente concentrado nos clientes que rec√©m entraram na base.\n",
    "\n",
    "## 3. MonthlyCharges e churn\n",
    "O boxplot indica:\n",
    "- Clientes churn possuem MonthlyCharges mais altos.\n",
    "- A mediana e o intervalo interquartil de churn s√£o superiores aos de n√£o churn.\n",
    "\n",
    "Conclus√£o: mensalidades altas aumentam a probabilidade de churn.\n",
    "\n",
    "## 4. TotalCharges e churn\n",
    "O violin plot mostra:\n",
    "- Clientes churn apresentam TotalCharges muito mais baixos.\n",
    "- Clientes n√£o churn concentram-se em valores altos de TotalCharges.\n",
    "\n",
    "Conclus√£o: churn est√° fortemente associado a clientes com pouco tempo de relacionamento (TotalCharges baixo √© um proxy de tenure baixo).\n",
    "\n",
    "## 5. Tipo de Internet e churn (InternetService reconstru√≠do)\n",
    "O gr√°fico de propor√ß√£o mostra tr√™s padr√µes:\n",
    "- Fiber optic apresenta a maior propor√ß√£o de churn.\n",
    "- DSL tem churn moderado.\n",
    "- No internet praticamente n√£o tem churn.\n",
    "\n",
    "Conclus√£o: o tipo de internet √© um driver importante, com fibra √≥ptica associada a maior insatisfa√ß√£o ou maior sensibilidade a pre√ßo.\n",
    "\n",
    "## 6. M√©todo de pagamento e churn\n",
    "O gr√°fico de PaymentMethod indica:\n",
    "- Clientes que utilizam Electronic check possuem propor√ß√£o significativamente maior de churn.\n",
    "- Os demais m√©todos apresentam churn bem menor.\n",
    "\n",
    "Conclus√£o: Electronic check √© um forte indicador de risco.\n",
    "\n",
    "## 7. Contrato (Contract reconstru√≠do)\n",
    "No gr√°fico reconstru√≠do:\n",
    "- Month-to-month apresenta claramente a maior propor√ß√£o de churn.\n",
    "- One year e Two year exibem churn drasticamente menor.\n",
    "\n",
    "Conclus√£o: contrato √© um dos fatores de reten√ß√£o mais relevantes: quanto mais longo, menor o churn.\n",
    "\n",
    "## 8. OnlineSecurity e churn\n",
    "O gr√°fico mostra:\n",
    "- Clientes sem OnlineSecurity t√™m churn visivelmente maior.\n",
    "- Clientes com OnlineSecurity churnam menos.\n",
    "\n",
    "Conclus√£o: seguran√ßa adicional funciona como um mecanismo de reten√ß√£o.\n",
    "\n",
    "## 9. TechSupport e churn\n",
    "O padr√£o √© semelhante ao anterior:\n",
    "- Aus√™ncia de TechSupport est√° associada a maior churn.\n",
    "- Clientes com suporte apresentam taxas menores.\n",
    "\n",
    "Conclus√£o: suporte t√©cnico reduz churn, possivelmente por aumentar valor percebido.\n",
    "\n",
    "## 10. StreamingTV e churn\n",
    "O gr√°fico mostra:\n",
    "- Pequena diferen√ßa de churn entre usar ou n√£o usar StreamingTV.\n",
    "- A vari√°vel n√£o apresenta impacto forte.\n",
    "\n",
    "Conclus√£o: StreamingTV √© um fator secund√°rio e n√£o parece explicar churn de maneira contundente.\n",
    "\n",
    "## 11. Heatmap de correla√ß√£o\n",
    "O heatmap confirma:\n",
    "- As correla√ß√µes de Pearson entre as vari√°veis num√©ricas e churn s√£o baixas ou nulas.\n",
    "- Isso √© esperado, pois churn √© uma vari√°vel bin√°ria com rela√ß√µes n√£o lineares.\n",
    "\n",
    "Conclus√£o: correla√ß√£o linear n√£o √© apropriada para medir rela√ß√£o com churn; os gr√°ficos categ√≥ricos capturam muito melhor os padr√µes.\n",
    "\n",
    "---\n",
    "\n",
    "# S√≠ntese Geral dos Principais Fatores de Churn\n",
    "\n",
    "## Fatores fortes (alta separa√ß√£o nos gr√°ficos)\n",
    "- Tenure baixo ‚Üí churn alto.\n",
    "- MonthlyCharges alto ‚Üí maior churn.\n",
    "- TotalCharges baixo ‚Üí churn alto (clientes novos).\n",
    "- InternetService = Fiber optic ‚Üí churn elevado.\n",
    "- PaymentMethod = Electronic check ‚Üí churn elevado.\n",
    "- Contract = Month-to-month ‚Üí maior churn da base.\n",
    "- Aus√™ncia de OnlineSecurity e TechSupport ‚Üí aumento do churn.\n",
    "\n",
    "## Fatores fracos\n",
    "- StreamingTV (impacto pequeno).\n",
    "- Outras vari√°veis num√©ricas n√£o mostram rela√ß√£o linear significativa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54ddd3d3-2dd9-43e6-b845-4490f442bf86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Escolha de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e7098db-514f-4faf-a070-0f6789281b51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# target\n",
    "y = df_clean[\"Churn\"]\n",
    "\n",
    "# features (excluindo target e textos)\n",
    "X = df_clean.drop(columns=[\"customerID\", \"Churn\", \"CustomerFeedback\", \"CustomerFeedback_clean\"])\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "boolean_cols = X.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"bool\", \"passthrough\", boolean_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"log_reg\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
    "    \"random_forest\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"xgboost\": XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"roc_auc\")\n",
    "    results[name] = scores\n",
    "    print(f\"{name} ‚Üí AUC m√©dio = {scores.mean():.4f} | std = {scores.std():.4f}\")\n",
    "\n",
    "best_model_name = max(results, key=lambda k: results[k].mean())\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(\"Melhor modelo:\", best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4264397b-13fe-430e-8556-c3d2b4f594d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Certifica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95b2d289-232c-4254-b95a-cd39930543b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "pipe_best = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", best_model)\n",
    "])\n",
    "\n",
    "pipe_best.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_best.predict(X_test)\\\n",
    "    \n",
    "y_proba = pipe_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "print(\"=== CERTIFICA√á√ÉO DO MODELO ===\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Matriz de confus√£o:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"=== COMPARA√á√ÉO COM DUMMY BASELINE ===\")\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "y_dummy = dummy.predict(X_test)\n",
    "y_dummy_prob = dummy.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Dummy Classifier (Most Frequent) ===\")\n",
    "print(classification_report(y_test, y_dummy, zero_division=0))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_dummy_prob))\n",
    "print(confusion_matrix(y_test, y_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d289d52-da25-484a-ad50-b204c2b3ba45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "plt.title(\"Curva ROC - Modelo Selecionado\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d2ad372-ea86-46a4-97f8-4c21ed9ea306",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Treinamento do modelo final com dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9e00c8c-19d2-4f5d-ab6e-10c2740d72de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== TREINANDO MODELO FINAL COM DATASET COMPLETO ===\")\n",
    "\n",
    "# Criar pipeline final com os mesmos par√¢metros do melhor modelo\n",
    "pipe_final = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", best_model)\n",
    "])\n",
    "\n",
    "# Treinar com 100% dos dados\n",
    "pipe_final.fit(X, y)\n",
    "\n",
    "print(f\"Modelo final treinado com {len(X)} amostras\")\n",
    "print(\"Pronto para infer√™ncia!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29fe99b3-fc45-47a0-93cc-462d76f2b2ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Registrar modelo no MLflow Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fb55c4b-72d4-4e7e-9dca-736bb332aa16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# usa o pipeline j√° treinado no notebook\n",
    "base_model = pipe_final  # seu pipeline treinado\n",
    "\n",
    "# exemplo de input para assinatura / input_example\n",
    "input_example = X.head(3)\n",
    "\n",
    "# wrapper que retorna DataFrame com prediction e probabilidades\n",
    "class ProbWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        # usamos o objeto em mem√≥ria (pipe_final)\n",
    "        self.model = base_model\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        # model_input √© um DataFrame com as mesmas colunas que seu pipeline espera\n",
    "        probs = self.model.predict_proba(model_input)  # shape (n, 2)\n",
    "        preds = self.model.predict(model_input)        # shape (n,)\n",
    "        # retornar um DataFrame para ficar claro no serving\n",
    "        out = pd.DataFrame({\n",
    "            \"prediction\": preds.astype(int),\n",
    "            \"prob_class0\": probs[:, 0],\n",
    "            \"prob_class1\": probs[:, 1]\n",
    "        })\n",
    "        return out\n",
    "\n",
    "# nome do registered model no workspace (novo nome para n√£o sobrescrever)\n",
    "registered_model_name = \"workspace_modelo_churn_with_probs\"\n",
    "\n",
    "with mlflow.start_run(run_name=\"register_pyfunc_probs\"):\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model_pyfunc_probs\",\n",
    "        python_model=ProbWrapper(),\n",
    "        registered_model_name=registered_model_name,\n",
    "        input_example=input_example.head(3),\n",
    "        signature=infer_signature(input_example.head(3),\n",
    "                                  base_model.predict_proba(input_example.head(3)))\n",
    "    )\n",
    "    mlflow.log_param(\"note\", \"pyfunc wrapper that returns prediction + probabilities\")\n",
    "\n",
    "print(\"Registrado:\", registered_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2134225a-52a9-4ff6-a873-c3b13ca4a6ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Aplica√ß√£o do Modelo Classificador ao dataset inference.csv e gera√ß√£o do Prediction.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ec0135-729e-4595-a7b4-28ccccd56000",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ==============================\n",
    "# 1) Fun√ß√£o de limpeza\n",
    "# ==============================\n",
    "def clean_like_history(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # tenure: 'unknown' -> NaN -> mediana -> int\n",
    "    if \"tenure\" in df.columns:\n",
    "        df[\"tenure\"] = df[\"tenure\"].replace(\"unknown\", np.nan)\n",
    "        df[\"tenure\"] = pd.to_numeric(df[\"tenure\"], errors=\"coerce\")\n",
    "        median_tenure = df[\"tenure\"].median()\n",
    "        df[\"tenure\"] = df[\"tenure\"].fillna(median_tenure).astype(int)\n",
    "\n",
    "    # TotalCharges: num√©rico + mediana\n",
    "    if \"TotalCharges\" in df.columns:\n",
    "        df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "        median_total = df[\"TotalCharges\"].median()\n",
    "        df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(median_total)\n",
    "\n",
    "    # bin√°rias Yes/No -> 0/1\n",
    "    binary_cols = [\n",
    "        \"PhoneService\", \"MultipleLines\", \"OnlineSecurity\", \"OnlineBackup\",\n",
    "        \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\",\n",
    "        \"Partner\", \"Dependents\", \"PaperlessBilling\"\n",
    "    ]\n",
    "    for col in binary_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map({\"Yes\": 1, \"No\": 0}).astype(float)\n",
    "\n",
    "    # texto limpo (se existir)\n",
    "    if \"CustomerFeedback\" in df.columns:\n",
    "        df[\"CustomerFeedback_clean\"] = (\n",
    "            df[\"CustomerFeedback\"]\n",
    "            .fillna(\"\")\n",
    "            .str.lower()\n",
    "            .str.replace(r\"[^0-9a-zA-Z ]\", \" \", regex=True)\n",
    "            .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "            .str.strip()\n",
    "        )\n",
    "\n",
    "    # dummies das categ√≥ricas\n",
    "    cat_cols = [\"gender\", \"InternetService\", \"Contract\", \"PaymentMethod\"]\n",
    "    cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "    if cat_cols:\n",
    "        df = pd.get_dummies(df, columns=cat_cols, drop_first=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ==============================\n",
    "# 2) Treinar modelo com history.csv\n",
    "# ==============================\n",
    "history_raw = pd.read_csv(\"./history.csv\")\n",
    "\n",
    "history_clean = clean_like_history(history_raw)\n",
    "\n",
    "# mapear Churn para 0/1\n",
    "if history_clean[\"Churn\"].dtype == \"O\":\n",
    "    history_clean[\"Churn\"] = history_clean[\"Churn\"].map({\"No\": 0, \"Yes\": 1}).astype(int)\n",
    "\n",
    "# opcional: salvar history_clean\n",
    "history_clean.to_csv(\"./history_clean.csv\", index=False)\n",
    "\n",
    "# definir features (tudo menos target, id e texto)\n",
    "drop_cols = [\"Churn\", \"customerID\", \"CustomerFeedback\", \"CustomerFeedback_clean\"]\n",
    "feature_cols = [c for c in history_clean.columns if c not in drop_cols]\n",
    "\n",
    "X_train = history_clean[feature_cols]\n",
    "y_train = history_clean[\"Churn\"]\n",
    "\n",
    "# medianas para imputa√ß√£o\n",
    "train_median = X_train.median(numeric_only=True)\n",
    "\n",
    "# ---------- IMPUTA√á√ÉO EM TREINO (para evitar NaN no fit) ----------\n",
    "for col in X_train.columns:\n",
    "    if col in train_median.index:\n",
    "        X_train[col] = X_train[col].fillna(train_median[col])\n",
    "\n",
    "# qualquer coisa ainda NaN -> 0\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "# pipeline: scaler + log√≠stica balanceada\n",
    "pipe_final = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "pipe_final.fit(X_train, y_train)\n",
    "print(\"Modelo treinado. Linhas:\", X_train.shape[0], \"| Features:\", X_train.shape[1])\n",
    "\n",
    "# ==============================\n",
    "# 3) Ler e limpar inference.csv\n",
    "# ==============================\n",
    "inference_raw = pd.read_csv(\"./inference.csv\")\n",
    "\n",
    "inference_clean = clean_like_history(inference_raw)\n",
    "\n",
    "# alinhar colunas com as do treino\n",
    "X_inf = inference_clean.reindex(columns=feature_cols, fill_value=0)\n",
    "\n",
    "# IMPUTA√á√ÉO EM INFER√äNCIA (consistente com treino)\n",
    "for col in X_inf.columns:\n",
    "    if col in train_median.index:\n",
    "        X_inf[col] = X_inf[col].fillna(train_median[col])\n",
    "\n",
    "X_inf = X_inf.fillna(0)\n",
    "\n",
    "# opcional: salvar vers√£o limpa de inference\n",
    "X_inf.to_csv(\"./inference_clean.csv\", index=False)\n",
    "\n",
    "# ==============================\n",
    "# 4) Prever churn com pipe_final\n",
    "# ==============================\n",
    "y_pred = pipe_final.predict(X_inf).astype(int)\n",
    "\n",
    "# ==============================\n",
    "# 5) Gerar prediction_grupo2.csv\n",
    "#    formato: ,customerID,prediction\n",
    "# ==============================\n",
    "pred_str = np.where(y_pred == 1, \"Yes\", \"No\")\n",
    "\n",
    "prediction_df = pd.DataFrame({\n",
    "    \"customerID\": inference_raw[\"customerID\"],\n",
    "    \"prediction\": pred_str\n",
    "})\n",
    "\n",
    "prediction_df.to_csv(\"./prediction_grupo2.csv\")\n",
    "print(\"prediction_grupo2.csv gerado no formato esperado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "495a8269-60f0-444b-b443-d8b77586408e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## MODELO DE MOTIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb15bdc3-0416-4063-a122-d4f18e19d71f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Carregar tabela de motivos (Delta)\n",
    "reason_df = spark.table(\"workspace.churn.churn_reason_final\").toPandas()\n",
    "\n",
    "# Visualizar\n",
    "reason_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "830a1c0a-746c-4134-98eb-4d91151de1f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_clean: seu dataset tratado com features finais (j√° visto no seu PDF)\n",
    "df_full = df_clean.copy()\n",
    "\n",
    "# garantir que customer_id est√° como string\n",
    "df_full[\"customerID\"] = df_full[\"customerID\"].astype(str)\n",
    "reason_df[\"customer_id\"] = reason_df[\"customer_id\"].astype(str)\n",
    "\n",
    "# juntar\n",
    "merged = df_full.merge(\n",
    "    reason_df[[\"customer_id\", \"churn_category\"]],\n",
    "    left_on=\"customerID\",\n",
    "    right_on=\"customer_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Merged shape antes de filtrar:\", merged.shape)\n",
    "\n",
    "# üî• remover classe rara direto aqui\n",
    "merged = merged[ merged[\"churn_category\"] != \"Other / unclear\" ].copy()\n",
    "\n",
    "print(\"Merged shape DEPOIS de filtrar:\", merged.shape)\n",
    "print(merged[\"churn_category\"].value_counts())\n",
    "merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07c16011-7f28-4e9e-a8f4-84c047db74dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_check = merged.copy()   # <-- seu dataset j√° alinhado\n",
    "\n",
    "print(\"=== SHAPE ===\")\n",
    "print(df_check.shape)\n",
    "\n",
    "print(\"\\n=== TIPOS ===\")\n",
    "print(df_check.dtypes)\n",
    "\n",
    "print(\"\\n=== COUNT DE NULOS POR COLUNA ===\")\n",
    "print(df_check.isna().sum())\n",
    "\n",
    "print(\"\\n=== LINHAS COM ALGUM NA ===\")\n",
    "print(df_check[df_check.isna().any(axis=1)].head())\n",
    "\n",
    "print(\"\\n=== CHECANDO VALORES INF E -INF ===\")\n",
    "num_df = df_check.select_dtypes(include=[np.number])\n",
    "print(np.isinf(num_df).sum())\n",
    "\n",
    "print(\"\\n=== CHECANDO STRINGS VAZIAS ===\")\n",
    "obj_cols = df_check.select_dtypes(include=['object']).columns\n",
    "empty_mask = df_check[obj_cols].apply(lambda col: col.astype(str).str.strip() == \"\")\n",
    "print(empty_mask.sum())\n",
    "\n",
    "print(\"\\n=== MOSTRAR VALORES ESTRANHOS NAS CATEGORIAS ===\")\n",
    "for col in obj_cols:\n",
    "    uniques = df_check[col].astype(str).str.strip().unique()\n",
    "    weird = [u for u in uniques if u in [\"\", \" \", \"None\", \"nan\", \"NaN\", \"NULL\", \"null\"]]\n",
    "    if weird:\n",
    "        print(f\"Coluna {col} tem valores suspeitos -> {weird}\")\n",
    "\n",
    "print(\"\\n=== CHECANDO MISTURA DE TIPOS NAS COLUNAS ===\")\n",
    "for col in df_check.columns:\n",
    "    types = df_check[col].apply(lambda x: type(x).__name__).unique()\n",
    "    if len(types) > 1:\n",
    "        print(f\"Coluna {col} tem mistura de tipos: {types}\")\n",
    "\n",
    "print(\"\\n=== CONTAGEM DE CLASSES NO TARGET ===\")\n",
    "if \"churn_category\" in df_check.columns:\n",
    "    print(df_check[\"churn_category\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\n=== EXEMPLOS DE LINHAS PROBLEM√ÅTICAS ===\")\n",
    "problem_rows = df_check[\n",
    "    df_check.isna().any(axis=1) |\n",
    "    empty_mask.any(axis=1)\n",
    "]\n",
    "print(problem_rows.head(20))\n",
    "\n",
    "print(\"\\n=== FIM DA VERIFICA√á√ÉO ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "211d2852-594f-4fda-b5c5-fdd0030e151a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# remover qualquer linha cujo churn_category √© None\n",
    "merged = merged[ merged[\"churn_category\"].notna() ].copy()\n",
    "\n",
    "# garantir que tudo virou string e est√° limpo\n",
    "merged[\"churn_category\"] = merged[\"churn_category\"].astype(str).str.strip()\n",
    "\n",
    "# reconstruir X e y\n",
    "y_reason = merged[\"churn_category\"]\n",
    "\n",
    "X_reason = merged.drop(columns=[\n",
    "    \"churn_category\",\n",
    "    \"customerID\",\n",
    "    \"customer_id\",\n",
    "    \"CustomerFeedback\",\n",
    "    \"CustomerFeedback_clean\",\n",
    "    \"reason_short\",\n",
    "    \"reason_long\"\n",
    "], errors=\"ignore\")\n",
    "\n",
    "print(\"Classes ap√≥s limpeza final:\")\n",
    "print(y_reason.value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab8987de-ac8b-49d7-b732-566d7117f9c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "numeric_cols = X_reason.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "bool_cols    = X_reason.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "\n",
    "numeric_cols, bool_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b5cf89-e4df-41b5-8ed4-8396e773b341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preprocess_reason = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"bool\", \"passthrough\", bool_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "models_reason = {\n",
    "    \"log_reg\": LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        class_weight=\"balanced\",\n",
    "        multi_class=\"auto\"\n",
    "    ),\n",
    "    \"random_forest\": RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"xgboost\": XGBClassifier(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebeb02e7-4723-43dc-8d0e-aa3eef2b05ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------- corre√ß√£o e run seguro para XGBoost --------------\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import traceback\n",
    "\n",
    "# 1) label-encode do target (para XGBoost)\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_reason.astype(str).str.strip())\n",
    "# mapa para interpreta√ß√£o posterior\n",
    "label_map = dict(enumerate(le.classes_))\n",
    "\n",
    "print(\"Label encoding feito. classes:\", label_map)\n",
    "\n",
    "# 2) substituir/configurar XGBoost \"seguro\" (se quiser persistir)\n",
    "safe_xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=42, n_estimators=200, verbosity=0)\n",
    "# se preferir, substitua no dicion√°rio models_reason:\n",
    "# models_reason['xgboost'] = safe_xgb\n",
    "\n",
    "# 3) cv seguro (ajusta n_splits conforme menor classe de y_reason original)\n",
    "min_count = int(y_reason.value_counts().min())\n",
    "n_splits = min(5, min_count) if min_count >= 2 else 2\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "print(\"Usando StratifiedKFold com n_splits =\", n_splits)\n",
    "\n",
    "# 4) loop robusto: usa y_enc para XGB e y_reason para os outros\n",
    "results = {}\n",
    "errors = {}\n",
    "\n",
    "for name, model in models_reason.items():\n",
    "    print(f\"\\n>>> Testando: {name} (tipo: {type(model)})\")\n",
    "    # se este for o XGB do dicion√°rio, use safe_xgb (opcional)\n",
    "    if 'xgboost' in name.lower():\n",
    "        model_to_use = safe_xgb\n",
    "        y_to_use = y_enc\n",
    "    else:\n",
    "        model_to_use = model\n",
    "        y_to_use = y_reason\n",
    "\n",
    "    pipe = Pipeline([(\"preprocess\", preprocess_reason), (\"model\", model_to_use)])\n",
    "    try:\n",
    "        scores = cross_val_score(pipe, X_reason, y_to_use, cv=cv, scoring=\"f1_macro\", error_score=np.nan)\n",
    "        mean = float(np.nanmean(scores))\n",
    "        std = float(np.nanstd(scores))\n",
    "        results[name] = (mean, std)\n",
    "        print(f\"  OK -> F1_macro = {mean:.4f} ¬± {std:.4f}  (scores: {scores})\")\n",
    "    except Exception as e:\n",
    "        tb = traceback.format_exc()\n",
    "        errors[name] = tb\n",
    "        results[name] = (np.nan, np.nan)\n",
    "        print(f\"  FALHOU -> {type(e).__name__}: {e}\")\n",
    "        print(tb[:1000])\n",
    "\n",
    "# 5) resumo e sele√ß√£o do melhor entre v√°lidos\n",
    "valid = {k:v for k,v in results.items() if not (np.isnan(v[0]))}\n",
    "\n",
    "print(\"\\n=== RESUMO ===\")\n",
    "for k,v in results.items():\n",
    "    status = \"VALID\" if k in valid else \"INVALID\"\n",
    "    print(k, \":\", status, \"->\", v)\n",
    "\n",
    "if not valid:\n",
    "    print(\"\\nNenhum modelo v√°lido. Tracebacks (resumidos):\")\n",
    "    for k,tb in errors.items():\n",
    "        print(f\"\\n--- {k} ---\\n{tb[:1000]}\")\n",
    "    raise RuntimeError(\"Nenhum modelo completou com sucesso.\")\n",
    "else:\n",
    "    best_name = max(valid, key=lambda k: valid[k][0])\n",
    "    print(\"\\n>>> MELHOR MODELO:\", best_name, \"->\", valid[best_name])\n",
    "\n",
    "    # se o melhor for xgboost e voc√™ quiser ver as classes originais:\n",
    "    if 'xgboost' in best_name.lower():\n",
    "        print(\"Observa√ß√£o: esse modelo usou labels codificados. Mapeamento label->classe:\")\n",
    "        for k,v in label_map.items():\n",
    "            print(k, \"->\", v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4034704-a75c-4f42-aafb-11660f899c94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reason, y_reason, test_size=0.2, stratify=y_reason, random_state=42\n",
    ")\n",
    "\n",
    "pipe_reason = Pipeline([\n",
    "    (\"preprocess\", preprocess_reason),\n",
    "    (\"model\", best_model)\n",
    "])\n",
    "\n",
    "pipe_reason.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_reason.predict(X_test)\n",
    "\n",
    "print(\"==== CERTIFICA√á√ÉO DO MODELO DE MOTIVOS ====\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34a921e7-9c4c-416c-bd6b-be071ac12496",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5616956058497166,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "marcos_notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
