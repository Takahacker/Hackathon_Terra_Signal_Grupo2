{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d99abd8-86e4-4307-8316-c109fae1b1ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Terra Signal Hackathon\n",
    "This notebook is provided as a starting point. Feel free to use it, discard it, modify it, or pretend it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e741f18-4b60-4e13-a3d9-041257455ebb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Pandas"
    }
   },
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14c40c2a-4dc2-42db-b4b1-92190de5a3f7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read file with pandas"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "file_path = \"./history.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52c25b6e-625e-41a5-8a8e-1b7ead6f3db7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e884fcf-b432-46c3-8d45-30c863f270d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d515decb-86f9-4525-ba88-a4aafbcf0e95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9ee06b5-ba75-4cb3-8ca3-082df5e23af1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# removendo coluna irrelevante\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.drop(columns=[\"customerID\"])\n",
    "\n",
    "# limpando a coluna 'tenure'\n",
    "\n",
    "# substituindo 'unknown' por NaN e convertendo para numérico\n",
    "df_clean[\"tenure\"] = df_clean[\"tenure\"].replace(\"unknown\", pd.NA)\n",
    "df_clean[\"tenure\"] = pd.to_numeric(df_clean[\"tenure\"], errors=\"coerce\")\n",
    "\n",
    "# substituindo valores 0 por NaN\n",
    "df_clean.loc[df_clean[\"tenure\"] == 0, \"tenure\"] = pd.NA\n",
    "\n",
    "# preenchendo NaN com a mediana e convertendo para inteiro\n",
    "df_clean[\"tenure\"] = df_clean[\"tenure\"].fillna(df_clean[\"tenure\"].median())\n",
    "df_clean[\"tenure\"] = df_clean[\"tenure\"].astype(int)\n",
    "\n",
    "# normalizando phone service\n",
    "df_clean[\"PhoneService\"] = (\n",
    "    df_clean[\"PhoneService\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .replace({\"yes\": 1, \"no\": 0})\n",
    "    .astype(int)  # <- evitar FutureWarning\n",
    ")\n",
    "\n",
    "# normalizando multiple lines\n",
    "df_clean[\"MultipleLines\"] = (\n",
    "    df_clean[\"MultipleLines\"]\n",
    "    .replace({\"No phone service\": \"No\"})\n",
    "    .map({\"Yes\": 1, \"No\": 0})\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# normalizando colunas de internet\n",
    "internet_cols = [\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
    "    \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"\n",
    "]\n",
    "\n",
    "for col in internet_cols:\n",
    "    df_clean[col] = (\n",
    "        df_clean[col]\n",
    "        .replace({\"No internet service\": \"No\"})\n",
    "        .map({\"Yes\": 1, \"No\": 0})\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "# normalizando colunas binárias\n",
    "for col in [\"Partner\", \"Dependents\", \"PaperlessBilling\"]:\n",
    "    df_clean[col] = df_clean[col].map({\"Yes\": 1, \"No\": 0}).astype(int)\n",
    "\n",
    "# convertendo total charges para numérico e tratando NaN\n",
    "df_clean[\"TotalCharges\"] = pd.to_numeric(df_clean[\"TotalCharges\"], errors=\"coerce\")\n",
    "df_clean[\"TotalCharges\"] = df_clean[\"TotalCharges\"].fillna(df_clean[\"TotalCharges\"].median())\n",
    "\n",
    "# limpando coluna de feedback do cliente\n",
    "df_clean[\"CustomerFeedback\"] = df_clean[\"CustomerFeedback\"].fillna(\"\").astype(str)\n",
    "df_clean[\"CustomerFeedback_clean\"] = (\n",
    "    df_clean[\"CustomerFeedback\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\"[^a-zA-Z0-9 ]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "# tratando categóricas com one-hot encoding\n",
    "cat_cols = [\n",
    "    \"gender\", \"InternetService\", \"Contract\", \"PaymentMethod\"\n",
    "]\n",
    "\n",
    "df_clean = pd.get_dummies(df_clean, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# convertendo target para binário\n",
    "df_clean[\"Churn\"] = df_clean[\"Churn\"].map({\"Yes\": 1, \"No\": 0}).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f87e535-555b-4378-b790-9f1e1af91742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8983367-3b89-4f76-8338-7bc3c824e8aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "606dfe70-0016-4cb9-a396-899be10285a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"history_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b48225-ae5e-4028-9d34-a9c7b77b1e38",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fake Model Example"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def prediction_function(input_df):\n",
    "    '''\n",
    "    An example model function, that just predicts randomly whether a customer will churn.\n",
    "    TODO: Make a better model.\n",
    "    '''\n",
    "    X = input_df[['customerID']].copy()\n",
    "    X['prediction'] = np.random.uniform(size=len(X)) >= 0.5\n",
    "    X['prediction'] = X['prediction'].map({True: 'Yes', False: 'No'})\n",
    "    return X\n",
    "\n",
    "test_df = pd.read_csv('inference.csv')\n",
    "prediction = prediction_function(test_df)\n",
    "print(prediction.head().transpose())\n",
    "# Use this code to save the prediction to a csv file for submission:\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "prediction.to_csv(f'prediction_<MY_GROUP_NAME>_{timestamp}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ddeda43-a1ee-48c8-aba0-38f958ac9675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "067e2b8b-05d1-4b2e-b842-3f5e210e5649",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(\n",
    "    data=df_clean,\n",
    "    x=\"Churn\",\n",
    "    hue=\"Churn\",\n",
    "    palette=\"Set2\",\n",
    "    legend=False\n",
    ")\n",
    "plt.title(\"Quantidade de Clientes: Churn vs Não Churn\")\n",
    "plt.xticks([0,1], [\"Não churn\", \"Churn\"])\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "595ea0cd-e7dd-4c42-9f50-2c10665167d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(\n",
    "    data=df_clean,\n",
    "    x=\"tenure\",\n",
    "    hue=\"Churn\",\n",
    "    multiple=\"stack\",\n",
    "    bins=40,\n",
    "    palette=\"Set2\"\n",
    ")\n",
    "plt.title(\"Distribuição de Tenure por Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "062ae05e-fbb9-4823-88dd-a71a0480ca8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(\n",
    "    data=df_clean,\n",
    "    x=\"Churn\",\n",
    "    y=\"MonthlyCharges\",\n",
    "    hue=\"Churn\",\n",
    "    palette=\"Set2\",\n",
    "    legend=False   # evita legenda duplicada\n",
    ")\n",
    "plt.title(\"MonthlyCharges por Churn\")\n",
    "plt.xticks([0,1], [\"Não churn\", \"Churn\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b6608e1-c9eb-4e50-93cf-aaff84448a6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.violinplot(data=df_clean, x=\"Churn\", y=\"TotalCharges\", hue=\"Churn\", palette=\"Set2\", legend=False)\n",
    "plt.title(\"Total Charges por Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ab6d9fe-8757-44fa-8311-a80cc3d34bbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# crosstab normalizada por linha (proporção)\n",
    "ct = pd.crosstab(\n",
    "    df_clean[\"InternetService_Fiber optic\"],\n",
    "    df_clean[\"Churn\"],\n",
    "    normalize='index'\n",
    ")\n",
    "\n",
    "# garantir ordem correta das colunas\n",
    "ct.columns = [\"No\", \"Yes\"]\n",
    "\n",
    "# definir cores (No = cinza, Yes = verde)\n",
    "colors = [\"#C0C0C0\", \"#2ECC71\"]\n",
    "\n",
    "# plotar com as cores desejadas\n",
    "ct.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(6,4),\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "plt.title(\"Composição: churn vs não churn — Fiber Optic (0 = não, 1 = sim)\")\n",
    "plt.ylabel(\"Proporção\")\n",
    "plt.xlabel(\"Fiber Optic\")\n",
    "plt.legend(title=\"Churn\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b629440d-f1ec-432d-9684-ec5ad8a95d74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ct2 = pd.crosstab(\n",
    "    df_clean[\"InternetService_No\"],\n",
    "    df_clean[\"Churn\"],\n",
    "    normalize='index'\n",
    ")\n",
    "\n",
    "# garantir ordem correta das colunas\n",
    "ct2.columns = [\"No\", \"Yes\"]\n",
    "\n",
    "# definir cores (No = cinza, Yes = verde)\n",
    "colors = [\"#C0C0C0\", \"#2ECC71\"]\n",
    "\n",
    "# plotar com as cores desejadas\n",
    "ct2.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(6,4),\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "plt.title(\"Composição: churn vs não churn — No Internet (0 = não, 1 = sim)\")\n",
    "plt.ylabel(\"Proporção\")\n",
    "plt.xlabel(\"No Internet\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(title=\"Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd3766e3-99e8-424d-8bc8-658e9a2b7813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "corr = df_clean.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", linewidths=.5)\n",
    "plt.title(\"Matriz de Correlação - Variáveis Numéricas\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53513b9f-05c7-4595-8051-11010b578399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(data=df_clean, x=\"Contract_Two year\", hue=\"Churn\")\n",
    "plt.title(\"Churn por tipo de contrato (Ex.: Two Year)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5879647-09c4-402f-8aa4-4f80f0b4b072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(data=df_clean, x=\"Contract_One year\", hue=\"Churn\")\n",
    "plt.title(\"Churn por tipo de contrato (One Year)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de7388b-69d9-49cb-a591-105bb9548939",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_clean[[\"tenure\",\"MonthlyCharges\",\"TotalCharges\",\"Churn\"]], hue=\"Churn\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0df8da6f-26f2-4c3a-acd8-4fe44d231b70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean_spark = spark.createDataFrame(df_clean)\n",
    "\n",
    "# mapeamento explícito dos nomes inválidos -> válidos\n",
    "rename_map = {\n",
    "    \"InternetService_Fiber optic\": \"InternetService_Fiber_optic\",\n",
    "    \"Contract_One year\": \"Contract_One_year\",\n",
    "    \"Contract_Two year\": \"Contract_Two_year\",\n",
    "    \"PaymentMethod_Credit card (automatic)\": \"PaymentMethod_Credit_card_automatic\",\n",
    "    \"PaymentMethod_Electronic check\": \"PaymentMethod_Electronic_check\",\n",
    "    \"PaymentMethod_Mailed check\": \"PaymentMethod_Mailed_check\",\n",
    "}\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "df_renamed = df_clean_spark\n",
    "for old, new in rename_map.items():\n",
    "    if old in df_renamed.columns:\n",
    "        df_renamed = df_renamed.withColumnRenamed(old, new)\n",
    "\n",
    "df_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f8688f1-bc8b-4db7-b91a-f063bcb29f77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# vou assumir que o DataFrame com esse schema se chama df_renamed\n",
    "df_renamed.printSchema()  # só pra garantir que é esse mesmo\n",
    "\n",
    "# 1) criar o schema (database) dentro do catálogo workspace\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS workspace.churn\")\n",
    "\n",
    "# 2) salvar como tabela gerenciada Delta\n",
    "tabela = \"workspace.churn.history_genie\"\n",
    "\n",
    "(df_renamed.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(tabela)\n",
    ")\n",
    "\n",
    "print(\"Tabela criada:\", tabela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0367e377-1904-4497-88e2-46c527fde6a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# tabela que você criou pro Genie\n",
    "df = (\n",
    "    spark.table(\"workspace.churn.history_genie\")\n",
    "          .select(\"Churn\", \"CustomerFeedback_clean\")\n",
    ")\n",
    "\n",
    "pdf = df.toPandas()\n",
    "pdf = pdf.dropna(subset=[\"CustomerFeedback_clean\"])\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d35b7b0d-749c-4640-ab1f-6dd10a749bcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf[\"tokens\"] = pdf[\"CustomerFeedback_clean\"].str.split()\n",
    "\n",
    "# 0 = não churn (positivo), 1 = churn (negativo)\n",
    "pdf_pos = pdf[pdf[\"Churn\"] == 0]\n",
    "pdf_neg = pdf[pdf[\"Churn\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7efad4a9-c8b3-4ed1-bc56-695c3f8f1829",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "pos_counts = Counter(\n",
    "    w\n",
    "    for tokens in pdf_pos[\"tokens\"]\n",
    "    for w in tokens\n",
    ")\n",
    "\n",
    "neg_counts = Counter(\n",
    "    w\n",
    "    for tokens in pdf_neg[\"tokens\"]\n",
    "    for w in tokens\n",
    ")\n",
    "\n",
    "len(pos_counts), len(neg_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fc816b8-2259-4d0a-ab8e-e9d8e8f7b600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "all_words = set(pos_counts) | set(neg_counts)\n",
    "\n",
    "total_pos = sum(pos_counts.values())\n",
    "total_neg = sum(neg_counts.values())\n",
    "V = len(all_words)  # vocabulário para suavização\n",
    "\n",
    "rows = []\n",
    "for w in all_words:\n",
    "    pos = pos_counts.get(w, 0)\n",
    "    neg = neg_counts.get(w, 0)\n",
    "    total = pos + neg\n",
    "\n",
    "    # filtra palavras muito raras (ajuste o limiar)\n",
    "    if total < 5:\n",
    "        continue\n",
    "\n",
    "    # probabilidades suavizadas\n",
    "    p_pos = (pos + 1) / (total_pos + V)\n",
    "    p_neg = (neg + 1) / (total_neg + V)\n",
    "\n",
    "    log_odds = np.log(p_neg / p_pos)\n",
    "\n",
    "    rows.append((w, pos, neg, total, log_odds))\n",
    "\n",
    "word_stats = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"word\", \"pos_count\", \"neg_count\", \"total\", \"log_odds\"]\n",
    ")\n",
    "\n",
    "word_stats.sort_values(\"log_odds\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceb03927-3a8f-4ca8-b39a-83e532050707",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8a757d7-a0f3-45b8-a113-960c8a44513e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# principais negativas\n",
    "neg_words = (\n",
    "    word_stats.sort_values(\"log_odds\", ascending=False)\n",
    "              .head(100)\n",
    ")\n",
    "\n",
    "# principais positivas\n",
    "pos_words = (\n",
    "    word_stats.sort_values(\"log_odds\", ascending=True)\n",
    "              .head(100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e63675-7eb5-46bc-a46a-11c5a34175b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dicionários palavra -> peso (uso total ou |log_odds|)\n",
    "pos_freq = {row.word: row.total for _, row in pos_words.iterrows()}\n",
    "neg_freq = {row.word: row.total for _, row in neg_words.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57d0d8f4-74e3-41f4-82d9-9f3a8933be4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wc_pos = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color=\"white\"\n",
    ").generate_from_frequencies(pos_freq)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc_pos, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Palavras mais associadas a NÃO churn (positivas)\")\n",
    "display(plt.gcf())\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdee0789-585f-49c3-922e-cf9d9b48684f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wc_neg = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color=\"white\"\n",
    ").generate_from_frequencies(neg_freq)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc_neg, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Palavras mais associadas a churn (negativas)\")\n",
    "display(plt.gcf())\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cecabd2-7c78-46e4-86c4-5b7bb37372af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_word_stats = spark.createDataFrame(word_stats)\n",
    "spark_word_stats.write.mode(\"overwrite\").saveAsTable(\"workspace.churn.word_polarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a4ff5af-c805-40a3-846e-ca127030ffe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install scikit-learn wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d4c5560-a11a-4a9e-9c03-a48c1b709d84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Naive Bayes de palavras (positivo x negativo) + WordCloud\n",
    "# Baseado na ideia do projeto Spark, mas em Python puro (sem Spark)\n",
    "# Usa a coluna \"CustomerFeedback_clean\" e \"Churn\" de um CSV\n",
    "#  - Churn = 0  -> feedback positivo (não churn)\n",
    "#  - Churn = 1  -> feedback negativo (churn)\n",
    "# ============================================\n",
    "\n",
    "# Instale as dependências (rode UMA vez no ambiente):\n",
    "# pip install pandas numpy wordcloud matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from math import log10\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Carregar dados\n",
    "# ------------------------------------------------\n",
    "# Ajuste o caminho do arquivo aqui:\n",
    "CSV_PATH = \"history_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Garante que as colunas necessárias existem\n",
    "col_label = \"Churn\"\n",
    "col_text  = \"CustomerFeedback_clean\"\n",
    "\n",
    "if col_label not in df.columns or col_text not in df.columns:\n",
    "    raise ValueError(f\"O CSV precisa ter as colunas '{col_label}' e '{col_text}'.\")\n",
    "\n",
    "# Remove linhas sem texto\n",
    "df = df.dropna(subset=[col_text])\n",
    "\n",
    "# Garante tipos corretos\n",
    "df[col_label] = df[col_label].astype(int)\n",
    "df[col_text]  = df[col_text].astype(str)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Construir contagens de palavras por classe (0 = não churn, 1 = churn)\n",
    "# ------------------------------------------------\n",
    "pos_counter = Counter()  # não churn (positivo)\n",
    "neg_counter = Counter()  # churn (negativo)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    label = row[col_label]\n",
    "    text  = row[col_text].lower()\n",
    "    tokens = text.split()\n",
    "    if label == 0:\n",
    "        for w in tokens:\n",
    "            pos_counter[w] += 1\n",
    "    elif label == 1:\n",
    "        for w in tokens:\n",
    "            neg_counter[w] += 1\n",
    "    # Se tiver outros valores de Churn, são ignorados\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Calcular log P(palavra | classe) com Laplace\n",
    "# ------------------------------------------------\n",
    "vocab = set(pos_counter.keys()) | set(neg_counter.keys())\n",
    "V = len(vocab)\n",
    "\n",
    "total_pos = sum(pos_counter.values())\n",
    "total_neg = sum(neg_counter.values())\n",
    "\n",
    "alpha = 1  # Laplace smoothing\n",
    "\n",
    "# modelo: word -> (log_prob_pos, log_prob_neg)\n",
    "modelo = {}\n",
    "\n",
    "for w in vocab:\n",
    "    c_pos = pos_counter.get(w, 0)\n",
    "    c_neg = neg_counter.get(w, 0)\n",
    "\n",
    "    # P(w | classe) com Laplace\n",
    "    p_pos = (c_pos + alpha) / (total_pos + alpha * V)\n",
    "    p_neg = (c_neg + alpha) / (total_neg + alpha * V)\n",
    "\n",
    "    log_p_pos = log10(p_pos)\n",
    "    log_p_neg = log10(p_neg)\n",
    "\n",
    "    modelo[w] = (log_p_pos, log_p_neg)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4. Função classificador (opcional, caso queira classificar textos)\n",
    "# ------------------------------------------------\n",
    "def classificar_texto(texto):\n",
    "    \"\"\"\n",
    "    Retorna 0 (não churn / positivo) ou 1 (churn / negativo)\n",
    "    com base no modelo Naive Bayes de palavras.\n",
    "    \"\"\"\n",
    "    texto = str(texto).lower()\n",
    "    tokens = texto.split()\n",
    "\n",
    "    score_pos = 0.0\n",
    "    score_neg = 0.0\n",
    "\n",
    "    for p in tokens:\n",
    "        if p in modelo:\n",
    "            log_p_pos, log_p_neg = modelo[p]\n",
    "            score_pos += log_p_pos\n",
    "            score_neg += log_p_neg\n",
    "\n",
    "    # Se a soma de log-probs for maior em churn, retorna 1 (negativo)\n",
    "    return 1 if score_neg > score_pos else 0\n",
    "\n",
    "# Exemplo de uso:\n",
    "# print(classificar_texto(\"service is terrible and very slow\"))\n",
    "# print(classificar_texto(\"great support, very happy\"))\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5. Medir polaridade de cada palavra (positivo x negativo)\n",
    "#    score = log P(w | churn=1) - log P(w | churn=0)\n",
    "#    score > 0 -> palavra mais associada a churn (negativa)\n",
    "#    score < 0 -> palavra mais associada a não churn (positiva)\n",
    "# ------------------------------------------------\n",
    "palavras = []\n",
    "log_pos_list = []\n",
    "log_neg_list = []\n",
    "score_list   = []\n",
    "count_list   = []\n",
    "\n",
    "for w, (log_p_pos, log_p_neg) in modelo.items():\n",
    "    score = log_p_neg - log_p_pos  # alinhado com \"negativo\" = churn\n",
    "    total_count = pos_counter.get(w, 0) + neg_counter.get(w, 0)\n",
    "    palavras.append(w)\n",
    "    log_pos_list.append(log_p_pos)\n",
    "    log_neg_list.append(log_p_neg)\n",
    "    score_list.append(score)\n",
    "    count_list.append(total_count)\n",
    "\n",
    "word_stats = pd.DataFrame({\n",
    "    \"word\": palavras,\n",
    "    \"log_prob_pos\": log_pos_list,\n",
    "    \"log_prob_neg\": log_neg_list,\n",
    "    \"score\": score_list,\n",
    "    \"count\": count_list\n",
    "})\n",
    "\n",
    "# Opcional: filtrar palavras muito raras\n",
    "min_count = 5\n",
    "word_stats = word_stats[word_stats[\"count\"] >= min_count].reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 6. Selecionar top palavras positivas e negativas\n",
    "# ------------------------------------------------\n",
    "TOP_N = 100\n",
    "\n",
    "# Negativas: mais associadas a churn (score alto)\n",
    "neg_words = word_stats.sort_values(\"score\", ascending=False).head(TOP_N)\n",
    "\n",
    "# Positivas: mais associadas a não churn (score bem negativo)\n",
    "pos_words = word_stats.sort_values(\"score\", ascending=True).head(TOP_N)\n",
    "\n",
    "print(\"Top 10 palavras NEGATIVAS (churn):\")\n",
    "print(neg_words[[\"word\", \"score\", \"count\"]].head(10))\n",
    "print(\"\\nTop 10 palavras POSITIVAS (não churn):\")\n",
    "print(pos_words[[\"word\", \"score\", \"count\"]].head(10))\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 7. WordCloud das principais palavras negativas e positivas\n",
    "#    Usamos |score| como peso (quanto mais forte a polaridade,\n",
    "#    maior a palavra na nuvem)\n",
    "# ------------------------------------------------\n",
    "neg_freq = {row.word: abs(row.score) for _, row in neg_words.iterrows()}\n",
    "pos_freq = {row.word: abs(row.score) for _, row in pos_words.iterrows()}\n",
    "\n",
    "# Nuvem de palavras NEGATIVAS (churn) – em VERMELHO\n",
    "wc_neg = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color=\"white\",\n",
    "    colormap=\"Reds\"  # <- paleta vermelha\n",
    ").generate_from_frequencies(neg_freq)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc_neg, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Palavras mais associadas a churn (negativas)\")\n",
    "plt.show()\n",
    "\n",
    "# Nuvem de palavras POSITIVAS (não churn) – em VERDE\n",
    "wc_pos = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color=\"white\",\n",
    "    colormap=\"Greens\"  # <- paleta verde\n",
    ").generate_from_frequencies(pos_freq)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc_pos, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Palavras mais associadas a NÃO churn (positivas)\")\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 8. (Opcional) Salvar a tabela de polaridade em CSV\n",
    "# ------------------------------------------------\n",
    "# word_stats.to_csv(\"word_polarity_naive_bayes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02a391fe-600d-4830-b287-b86aa0877347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8217042190192805,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Gustavo",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
